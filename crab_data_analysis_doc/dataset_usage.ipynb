{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ab743b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    _to_dict,\n",
    "    _donut,\n",
    "    _pie,\n",
    "    _line_graph,\n",
    "    _other_fields,\n",
    "    _exitcode_info\n",
    ")\n",
    "from datetime import datetime, date, timedelta\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    lit,\n",
    "    when,\n",
    "    sum as _sum,\n",
    "    count as _count,\n",
    "    first,\n",
    "    date_format,\n",
    "    from_unixtime,\n",
    "    to_date\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    LongType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    DoubleType,\n",
    "    IntegerType,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5dbc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c072ace",
   "metadata": {},
   "source": [
    "Which are the 5 (10) most used datasets[DESIRED_CMSDataset] in the last week/month[RecordTime]... etc. ? How much CPU time[CpuTimeHr]*[RequestCpus]=[CoreHr],[WallClockHr] was spent on those ? Which fraction of the total ? How big are those ?[Size] How many users/tasks hit each dataset ?[User][CRAB_LumiMask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ab3ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_schema():\n",
    "    return StructType(\n",
    "        [\n",
    "            StructField(\n",
    "                \"data\",\n",
    "                StructType(\n",
    "                    [\n",
    "                        StructField(\"RecordTime\", LongType(), nullable=False),\n",
    "                        StructField(\"InputData\", StringType(), nullable=True),\n",
    "                        StructField(\"Status\", StringType(), nullable=True),\n",
    "                        StructField(\"DESIRED_CMSDataset\", StringType(), nullable=True),\n",
    "                        StructField(\"CpuTimeHr\", DoubleType(), nullable=True),\n",
    "                        StructField(\"RequestCpus\", LongType(), nullable=True),\n",
    "                        StructField(\"GlobalJobId\", StringType(), nullable=False),\n",
    "                        StructField(\"CMS_SubmissionTool\", StringType(), nullable=True)\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f437426",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DEFAULT_HDFS_FOLDER = \"/project/monitoring/archive/condor/raw/metric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b01b84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_files(start_date, end_date, spark, base=_DEFAULT_HDFS_FOLDER):\n",
    "    st_date = start_date - timedelta(days=3)\n",
    "    ed_date = end_date + timedelta(days=3)\n",
    "    days = (ed_date - st_date).days\n",
    "    pre_candidate_files = [\n",
    "        \"{base}/{day}{{,.tmp}}\".format(\n",
    "            base=base, day=(st_date + timedelta(days=i)).strftime(\"%Y/%m/%d\")\n",
    "        )\n",
    "        for i in range(0, days)\n",
    "    ]\n",
    "    sc = spark.sparkContext\n",
    "    candidate_files = [\n",
    "        f\"{base}/{(st_date + timedelta(days=i)).strftime('%Y/%m/%d')}\"\n",
    "        for i in range(0, days)\n",
    "    ]\n",
    "    FileSystem = sc._gateway.jvm.org.apache.hadoop.fs.FileSystem\n",
    "    URI = sc._gateway.jvm.java.net.URI\n",
    "    Path = sc._gateway.jvm.org.apache.hadoop.fs.Path\n",
    "    fs = FileSystem.get(URI(\"hdfs:///\"), sc._jsc.hadoopConfiguration())\n",
    "    candidate_files = [url for url in candidate_files if fs.globStatus(Path(url))]\n",
    "    return candidate_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5408bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = _get_schema()\n",
    "start_date = datetime(2022, 5, 1)\n",
    "end_date = datetime(2022, 5, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bbf04ad",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/project/monitoring/archive/condor/raw/metric/2022/04/28',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/04/29',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/04/30',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/05/01',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/05/02',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/05/03',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/05/04',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/05/05',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/05/06',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/05/07',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/05/08',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/05/09',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/05/10']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_candidate_files(start_date, end_date, spark, base=_DEFAULT_HDFS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07763e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = (\n",
    "        spark.read.option(\"basePath\", _DEFAULT_HDFS_FOLDER)\n",
    "        .json(\n",
    "            get_candidate_files(start_date, end_date, spark, base=_DEFAULT_HDFS_FOLDER),\n",
    "            schema=schema,\n",
    "        ).select(\"data.*\")\n",
    "        .filter(\n",
    "            f\"\"\"RecordTime >= {start_date.timestamp() * 1000}\n",
    "          AND RecordTime < {end_date.timestamp() * 1000}\n",
    "          \"\"\"\n",
    "        )\n",
    "        .drop_duplicates([\"GlobalJobId\"])\n",
    "    )\n",
    "\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e011bbbf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordTime: long (nullable = true)\n",
      " |-- InputData: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- DESIRED_CMSDataset: string (nullable = true)\n",
      " |-- CpuTimeHr: double (nullable = true)\n",
      " |-- RequestCpus: long (nullable = true)\n",
      " |-- GlobalJobId: string (nullable = true)\n",
      " |-- CMS_SubmissionTool: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc1d2d51",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "| CMS_SubmissionTool|\n",
      "+-------------------+\n",
      "|               CRAB|\n",
      "|InstitutionalSchedd|\n",
      "|         CMSConnect|\n",
      "|            WMAgent|\n",
      "|          Condor_SI|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = raw_df.select(col('CMS_SubmissionTool')).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be4278",
   "metadata": {},
   "source": [
    "### df1 - time range 05/01 - 05/08 (7days) - show sum_CpuTimeHr used by each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73a897ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = raw_df.withColumn(\"timestamp\", date_format(from_unixtime(col('RecordTime')/1000), \"dd\"))\\\n",
    "            .select(col('timestamp'),\\\n",
    "                    col('DESIRED_CMSDataset'),\\\n",
    "                    col('CpuTimeHr'))\\\n",
    "            .groupby(col('timestamp'), col('DESIRED_CMSDataset'))\\\n",
    "            .agg(_sum(\"CpuTimeHr\").alias(\"Sum_CpuTimeHr\"))\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee29e116",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- DESIRED_CMSDataset: string (nullable = true)\n",
      " |-- Sum_CpuTimeHr: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0163e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F     \n",
    "week_Sum = df1.agg(F.sum(\"Sum_CpuTimeHr\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "171ee45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_Sum_CpuTimeHr = df1.groupby(col('timestamp')).agg(F.sum(\"Sum_CpuTimeHr\")).orderBy(col('timestamp')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "387979f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(timestamp='01', sum(Sum_CpuTimeHr)=3237665.5605555526),\n",
       " Row(timestamp='02', sum(Sum_CpuTimeHr)=2405833.891111112),\n",
       " Row(timestamp='03', sum(Sum_CpuTimeHr)=2780124.6286111106),\n",
       " Row(timestamp='04', sum(Sum_CpuTimeHr)=1640770.8308333335),\n",
       " Row(timestamp='05', sum(Sum_CpuTimeHr)=1856863.838611111),\n",
       " Row(timestamp='06', sum(Sum_CpuTimeHr)=2425978.531666666),\n",
       " Row(timestamp='07', sum(Sum_CpuTimeHr)=2002801.1166666658),\n",
       " Row(timestamp='30', sum(Sum_CpuTimeHr)=570767.4969444439)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_Sum_CpuTimeHr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5bee9e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView(\"df1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f566dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_Top5_CpuTimeHr = spark.sql(\"(SELECT * FROM df1 WHERE df1.timestamp=='30' ORDER BY df1.Sum_CpuTimeHr DESC LIMIT 5)\\\n",
    "                        UNION ALL (SELECT * FROM df1 WHERE df1.timestamp=='01' ORDER BY df1.Sum_CpuTimeHr DESC LIMIT 5)\\\n",
    "                        UNION ALL (SELECT * FROM df1 WHERE df1.timestamp=='02' ORDER BY df1.Sum_CpuTimeHr DESC LIMIT 5)\\\n",
    "                        UNION ALL (SELECT * FROM df1 WHERE df1.timestamp=='03' ORDER BY df1.Sum_CpuTimeHr DESC LIMIT 5)\\\n",
    "                        UNION ALL (SELECT * FROM df1 WHERE df1.timestamp=='04' ORDER BY df1.Sum_CpuTimeHr DESC LIMIT 5)\\\n",
    "                        UNION ALL (SELECT * FROM df1 WHERE df1.timestamp=='05' ORDER BY df1.Sum_CpuTimeHr DESC LIMIT 5)\\\n",
    "                        UNION ALL (SELECT * FROM df1 WHERE df1.timestamp=='06' ORDER BY df1.Sum_CpuTimeHr DESC LIMIT 5)\\\n",
    "                        UNION ALL (SELECT * FROM df1 WHERE df1.timestamp=='07' ORDER BY df1.Sum_CpuTimeHr DESC LIMIT 5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a4a8209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = ['May 1st Week', '30/04', '01/05','02/05', '03/05', '04/05', '05/05', '06/05', '07/05']\n",
    "for i in ['30', '01', '02', '03', '04', '05', '06', '07']:\n",
    "    for j in range(1, 6):\n",
    "        Labels.append('%s - Top%d' % (i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6487c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "Values = [week_Sum]\n",
    "Values.append(daily_Sum_CpuTimeHr[7]['sum(Sum_CpuTimeHr)'])\n",
    "for i in daily_Sum_CpuTimeHr:\n",
    "    if(i['timestamp']=='30'):\n",
    "        break\n",
    "    else:\n",
    "        Values.append(i['sum(Sum_CpuTimeHr)'])\n",
    "Values.extend(daily_Top5_CpuTimeHr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bdaf1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parents = [\"\"]\n",
    "for i in range(8):\n",
    "    Parents.append(\"May 1st Week\")\n",
    "for k in ['30/04', '01/05','02/05', '03/05', '04/05', '05/05', '06/05', '07/05']:\n",
    "    for j in range(5):\n",
    "        Parents.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ffdf1831",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hover = ['May 1st Week', '30/04', '01/05','02/05', '03/05', '04/05', '05/05', '06/05', '07/05']\n",
    "Hover.extend(daily_Top5_Dataset_list)\n",
    "for i in range(49):\n",
    "    x = \" - CPU Time: %.3f\"%(Values[i])\n",
    "    Hover[i] = f'{Hover[i]}{x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d5e9ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sum(Values)-Values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ed883946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-97856.37749999762"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x - Values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dff9a6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/20 15:26:02 ERROR YarnScheduler: Lost executor 136 on ithdp1111.cern.ch: Container from a bad node: container_e136_1658221000868_4354_01_000178 on host: ithdp1111.cern.ch. Exit status: 137. Diagnostics: [2022-07-20 15:26:01.975]Container killed on request. Exit code is 137\n",
      "[2022-07-20 15:26:02.023]Container exited with a non-zero exit code 137. \n",
      "[2022-07-20 15:26:02.027]Killed by external signal\n",
      ".\n",
      "22/07/20 15:26:02 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 136 for reason Container from a bad node: container_e136_1658221000868_4354_01_000178 on host: ithdp1111.cern.ch. Exit status: 137. Diagnostics: [2022-07-20 15:26:01.975]Container killed on request. Exit code is 137\n",
      "[2022-07-20 15:26:02.023]Container exited with a non-zero exit code 137. \n",
      "[2022-07-20 15:26:02.027]Killed by external signal\n",
      ".\n",
      "22/07/20 15:26:02 WARN TaskSetManager: Lost task 80.0 in stage 47.0 (TID 9426) (ithdp1111.cern.ch executor 136): ExecutorLostFailure (executor 136 exited caused by one of the running tasks) Reason: Container from a bad node: container_e136_1658221000868_4354_01_000178 on host: ithdp1111.cern.ch. Exit status: 137. Diagnostics: [2022-07-20 15:26:01.975]Container killed on request. Exit code is 137\n",
      "[2022-07-20 15:26:02.023]Container exited with a non-zero exit code 137. \n",
      "[2022-07-20 15:26:02.027]Killed by external signal\n",
      ".\n",
      "22/07/20 15:26:02 WARN TaskSetManager: Lost task 89.0 in stage 47.0 (TID 9435) (ithdp1111.cern.ch executor 136): ExecutorLostFailure (executor 136 exited caused by one of the running tasks) Reason: Container from a bad node: container_e136_1658221000868_4354_01_000178 on host: ithdp1111.cern.ch. Exit status: 137. Diagnostics: [2022-07-20 15:26:01.975]Container killed on request. Exit code is 137\n",
      "[2022-07-20 15:26:02.023]Container exited with a non-zero exit code 137. \n",
      "[2022-07-20 15:26:02.027]Killed by external signal\n",
      ".\n",
      "22/07/20 15:26:02 WARN TaskSetManager: Lost task 87.0 in stage 47.0 (TID 9433) (ithdp1111.cern.ch executor 136): ExecutorLostFailure (executor 136 exited caused by one of the running tasks) Reason: Container from a bad node: container_e136_1658221000868_4354_01_000178 on host: ithdp1111.cern.ch. Exit status: 137. Diagnostics: [2022-07-20 15:26:01.975]Container killed on request. Exit code is 137\n",
      "[2022-07-20 15:26:02.023]Container exited with a non-zero exit code 137. \n",
      "[2022-07-20 15:26:02.027]Killed by external signal\n",
      ".\n",
      "22/07/20 15:26:02 WARN TaskSetManager: Lost task 74.0 in stage 47.0 (TID 9420) (ithdp1111.cern.ch executor 136): ExecutorLostFailure (executor 136 exited caused by one of the running tasks) Reason: Container from a bad node: container_e136_1658221000868_4354_01_000178 on host: ithdp1111.cern.ch. Exit status: 137. Diagnostics: [2022-07-20 15:26:01.975]Container killed on request. Exit code is 137\n",
      "[2022-07-20 15:26:02.023]Container exited with a non-zero exit code 137. \n",
      "[2022-07-20 15:26:02.027]Killed by external signal\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "daily_Top5_CpuTimeHr_list = daily_Top5_CpuTimeHr.select('Sum_CpuTimeHr').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80d66427",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/20 15:30:44 ERROR YarnScheduler: Lost executor 127 on ithdp5006.cern.ch: Container from a bad node: container_e136_1658221000868_4354_01_000165 on host: ithdp5006.cern.ch. Exit status: 137. Diagnostics: [2022-07-20 15:30:44.752]Container killed on request. Exit code is 137\n",
      "[2022-07-20 15:30:44.808]Container exited with a non-zero exit code 137. \n",
      "[2022-07-20 15:30:44.811]Killed by external signal\n",
      ".\n",
      "22/07/20 15:30:44 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 127 for reason Container from a bad node: container_e136_1658221000868_4354_01_000165 on host: ithdp5006.cern.ch. Exit status: 137. Diagnostics: [2022-07-20 15:30:44.752]Container killed on request. Exit code is 137\n",
      "[2022-07-20 15:30:44.808]Container exited with a non-zero exit code 137. \n",
      "[2022-07-20 15:30:44.811]Killed by external signal\n",
      ".\n",
      "22/07/20 15:30:44 WARN TaskSetManager: Lost task 83.0 in stage 63.0 (TID 11372) (ithdp5006.cern.ch executor 127): ExecutorLostFailure (executor 127 exited caused by one of the running tasks) Reason: Container from a bad node: container_e136_1658221000868_4354_01_000165 on host: ithdp5006.cern.ch. Exit status: 137. Diagnostics: [2022-07-20 15:30:44.752]Container killed on request. Exit code is 137\n",
      "[2022-07-20 15:30:44.808]Container exited with a non-zero exit code 137. \n",
      "[2022-07-20 15:30:44.811]Killed by external signal\n",
      ".\n",
      "22/07/20 15:30:44 WARN TaskSetManager: Lost task 115.0 in stage 63.0 (TID 11404) (ithdp5006.cern.ch executor 127): ExecutorLostFailure (executor 127 exited caused by one of the running tasks) Reason: Container from a bad node: container_e136_1658221000868_4354_01_000165 on host: ithdp5006.cern.ch. Exit status: 137. Diagnostics: [2022-07-20 15:30:44.752]Container killed on request. Exit code is 137\n",
      "[2022-07-20 15:30:44.808]Container exited with a non-zero exit code 137. \n",
      "[2022-07-20 15:30:44.811]Killed by external signal\n",
      ".\n",
      "22/07/20 15:30:44 WARN TaskSetManager: Lost task 19.0 in stage 63.0 (TID 11308) (ithdp5006.cern.ch executor 127): ExecutorLostFailure (executor 127 exited caused by one of the running tasks) Reason: Container from a bad node: container_e136_1658221000868_4354_01_000165 on host: ithdp5006.cern.ch. Exit status: 137. Diagnostics: [2022-07-20 15:30:44.752]Container killed on request. Exit code is 137\n",
      "[2022-07-20 15:30:44.808]Container exited with a non-zero exit code 137. \n",
      "[2022-07-20 15:30:44.811]Killed by external signal\n",
      ".\n",
      "22/07/20 15:30:44 WARN TaskSetManager: Lost task 51.0 in stage 63.0 (TID 11340) (ithdp5006.cern.ch executor 127): ExecutorLostFailure (executor 127 exited caused by one of the running tasks) Reason: Container from a bad node: container_e136_1658221000868_4354_01_000165 on host: ithdp5006.cern.ch. Exit status: 137. Diagnostics: [2022-07-20 15:30:44.752]Container killed on request. Exit code is 137\n",
      "[2022-07-20 15:30:44.808]Container exited with a non-zero exit code 137. \n",
      "[2022-07-20 15:30:44.811]Killed by external signal\n",
      ".\n",
      "22/07/20 15:30:45 WARN TaskSetManager: Lost task 13.0 in stage 63.0 (TID 11302) (ithdp5008.cern.ch executor 139): FetchFailed(BlockManagerId(127, ithdp5006.cern.ch, 7337, None), shuffleId=35, mapIndex=459, mapId=459, reduceId=13, message=\n",
      "org.apache.spark.shuffle.FetchFailedException: Stream is corrupted\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.read(ShuffleBlockFetcherIterator.scala:845)\n",
      "\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n",
      "\tat java.io.BufferedInputStream.read1(BufferedInputStream.java:286)\n",
      "\tat java.io.BufferedInputStream.read(BufferedInputStream.java:345)\n",
      "\tat java.io.DataInputStream.read(DataInputStream.java:149)\n",
      "\tat org.sparkproject.guava.io.ByteStreams.read(ByteStreams.java:899)\n",
      "\tat org.sparkproject.guava.io.ByteStreams.readFully(ByteStreams.java:733)\n",
      "\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2$$anon$3.next(UnsafeRowSerializer.scala:127)\n",
      "\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2$$anon$3.next(UnsafeRowSerializer.scala:110)\n",
      "\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:494)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat org.apache.spark.InterruptibleIterator.next(InterruptibleIterator.scala:40)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$2(SortAggregateExec.scala:59)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$2$adapted(SortAggregateExec.scala:56)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:885)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:885)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.io.IOException: Stream is corrupted\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:250)\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.read(LZ4BlockInputStream.java:157)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.read(ShuffleBlockFetcherIterator.scala:841)\n",
      "\t... 40 more\n",
      "Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 8642 of input buffer\n",
      "\tat net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:245)\n",
      "\t... 42 more\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 75.0 in stage 55.0 (TID 11507) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=75, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 71.0 in stage 55.0 (TID 11503) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=71, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 78.0 in stage 55.0 (TID 11510) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=78, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 92.0 in stage 55.0 (TID 11525) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=92, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 98.0 in stage 55.0 (TID 11531) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=98, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 105.0 in stage 55.0 (TID 11538) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=105, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 94.0 in stage 55.0 (TID 11527) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=94, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 1.0 in stage 57.0 (TID 11540) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=1, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 0.0 in stage 57.0 (TID 11539) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=0, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 6.0 in stage 57.0 (TID 11545) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=6, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 4.0 in stage 57.0 (TID 11543) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=4, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 1.0 in stage 59.0 (TID 11547) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=1, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 0.0 in stage 59.0 (TID 11546) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=0, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 2.0 in stage 59.0 (TID 11548) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=2, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 3.0 in stage 57.0 (TID 11542) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=3, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 5.0 in stage 57.0 (TID 11544) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=5, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 2.0 in stage 57.0 (TID 11541) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=2, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 3.0 in stage 59.0 (TID 11549) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=3, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 0.0 in stage 61.0 (TID 11550) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=0, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 1.0 in stage 61.0 (TID 11551) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=1, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 4.0 in stage 61.0 (TID 11554) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=4, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 3.0 in stage 61.0 (TID 11553) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=3, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 2.0 in stage 61.0 (TID 11552) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=2, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 6.0 in stage 61.0 (TID 11556) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=6, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 5.0 in stage 61.0 (TID 11555) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=5, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 5.0 in stage 65.0 (TID 11562) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=5, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 0.0 in stage 65.0 (TID 11557) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=0, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 4.0 in stage 65.0 (TID 11561) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=4, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 6.0 in stage 65.0 (TID 11563) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=6, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 2.0 in stage 65.0 (TID 11559) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=2, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 1.0 in stage 65.0 (TID 11558) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=1, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 3.0 in stage 65.0 (TID 11560) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=3, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 1.0 in stage 67.0 (TID 11565) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=1, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 0.0 in stage 67.0 (TID 11564) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=0, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 2.0 in stage 67.0 (TID 11566) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=2, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 4.0 in stage 67.0 (TID 11568) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=4, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 5.0 in stage 67.0 (TID 11569) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=5, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 3.0 in stage 67.0 (TID 11567) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=3, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 6.0 in stage 67.0 (TID 11570) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=6, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 0.0 in stage 69.0 (TID 11571) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=0, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 1.0 in stage 69.0 (TID 11572) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=1, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 5.0 in stage 69.0 (TID 11576) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=5, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 23.0 in stage 55.0 (TID 11451) (ithdp4021.cern.ch executor 142): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=23, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 31.0 in stage 55.0 (TID 11461) (ithdp4021.cern.ch executor 142): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=31, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 33.0 in stage 55.0 (TID 11463) (ithdp4021.cern.ch executor 142): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=33, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 3.0 in stage 69.0 (TID 11574) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=3, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 2.0 in stage 69.0 (TID 11573) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=2, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 6.0 in stage 69.0 (TID 11577) (ithdp2107.cern.ch executor 154): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=6, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 4.0 in stage 69.0 (TID 11575) (ithdp1111.cern.ch executor 143): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=4, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 55.0 in stage 55.0 (TID 11486) (ithdp5006.cern.ch executor 134): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=55, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 74.0 in stage 55.0 (TID 11506) (ithdp5006.cern.ch executor 134): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=74, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 62.0 in stage 55.0 (TID 11494) (ithdp5006.cern.ch executor 134): FetchFailed(null, shuffleId=35, mapIndex=-1, mapId=-1, reduceId=62, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 35\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:190)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "22/07/20 15:30:47 WARN TaskSetManager: Lost task 13.0 in stage 55.0 (TID 11439) (ithdp5008.cern.ch executor 145): FetchFailed(BlockManagerId(127, ithdp5006.cern.ch, 7337, None), shuffleId=35, mapIndex=459, mapId=459, reduceId=13, message=\n",
      "org.apache.spark.shuffle.FetchFailedException: Stream is corrupted\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.read(ShuffleBlockFetcherIterator.scala:845)\n",
      "\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n",
      "\tat java.io.BufferedInputStream.read1(BufferedInputStream.java:286)\n",
      "\tat java.io.BufferedInputStream.read(BufferedInputStream.java:345)\n",
      "\tat java.io.DataInputStream.read(DataInputStream.java:149)\n",
      "\tat org.sparkproject.guava.io.ByteStreams.read(ByteStreams.java:899)\n",
      "\tat org.sparkproject.guava.io.ByteStreams.readFully(ByteStreams.java:733)\n",
      "\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2$$anon$3.next(UnsafeRowSerializer.scala:127)\n",
      "\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2$$anon$3.next(UnsafeRowSerializer.scala:110)\n",
      "\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:494)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat org.apache.spark.InterruptibleIterator.next(InterruptibleIterator.scala:40)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage22.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage22.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$2(SortAggregateExec.scala:59)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$2$adapted(SortAggregateExec.scala:56)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:885)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:885)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.io.IOException: Stream is corrupted\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:250)\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.read(LZ4BlockInputStream.java:157)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.read(ShuffleBlockFetcherIterator.scala:841)\n",
      "\t... 40 more\n",
      "Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 8642 of input buffer\n",
      "\tat net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:245)\n",
      "\t... 42 more\n",
      "\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "daily_Top5_Dataset_list = daily_Top5_CpuTimeHr.select('DESIRED_CMSDataset').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7794044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(daily_Top5_Dataset_list)):\n",
    "    if (daily_Top5_Dataset_list[i] is None):\n",
    "        daily_Top5_Dataset_list[i] = \"Null\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "28d5910f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "branchvalues": "total",
         "hovertemplate": [
          "May 1st Week - CPU Time: 17230754.609",
          "30/04 - CPU Time: 570767.497",
          "01/05 - CPU Time: 3237665.561",
          "02/05 - CPU Time: 2405833.891",
          "03/05 - CPU Time: 2780124.629",
          "04/05 - CPU Time: 1640770.831",
          "05/05 - CPU Time: 1856863.839",
          "06/05 - CPU Time: 2425978.532",
          "07/05 - CPU Time: 2002801.117",
          "Null - CPU Time: 525436.415",
          "/TTJets_TuneCP5_13TeV-amcatnloFXFX-pythia8/RunIISummer20UL17MiniAOD-106X_mc2017_realistic_v6-v2/MINIAODSIM - CPU Time: 8444.535",
          "/MuOnia/Run2018A-v1/RAW - CPU Time: 7913.050",
          "/Charmonium/Run2018A-v1/RAW - CPU Time: 5497.065",
          "/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL17MiniAOD-106X_mc2017_realistic_v6-v2/MINIAODSIM - CPU Time: 4336.978",
          "Null - CPU Time: 2391008.125",
          "/MuOnia/Run2018A-v1/RAW - CPU Time: 35902.691",
          "/Tau/Run2018A-v1/RAW - CPU Time: 33715.245",
          "/Tau/Run2018B-v1/RAW - CPU Time: 28417.584",
          "/Tau/Run2018C-v1/RAW - CPU Time: 22874.277",
          "Null - CPU Time: 1914446.371",
          "/EGamma/Run2018C-v1/RAW - CPU Time: 30692.127",
          "/Tau/Run2018A-v1/RAW - CPU Time: 27810.123",
          "/Charmonium/Run2018D-v1/RAW - CPU Time: 22828.950",
          "/SingleMuon/Run2018A-UL2018_MiniAODv2-v3/MINIAOD - CPU Time: 22618.157",
          "Null - CPU Time: 2324922.709",
          "/EGamma/Run2018C-v1/RAW - CPU Time: 61326.856",
          "/EGamma/Run2018D-12Nov2019_UL2018-v4/MINIAOD - CPU Time: 32056.297",
          "/Tau/Run2018A-v1/RAW - CPU Time: 24778.929",
          "/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18MiniAODv2-106X_upgrade2018_realistic_v16_L1v1-v2/MINIAODSIM - CPU Time: 23074.572",
          "Null - CPU Time: 1220947.469",
          "/PMSSM_set_2_LL_2_TuneCP2_13TeV-pythia8/RunIIFall17MiniAODv2-PUFall17Fast_GridpackScan_94X_mc2017_realistic_v15-v2/MINIAODSIM - CPU Time: 22284.813",
          "/EGamma/Run2018D-12Nov2019_UL2018-v4/MINIAOD - CPU Time: 18760.714",
          "/EGamma/Run2018C-v1/RAW - CPU Time: 16905.317",
          "/Tau/Run2018A-v1/RAW - CPU Time: 11880.745",
          "Null - CPU Time: 1361493.080",
          "/EGamma/Run2018D-v1/RAW - CPU Time: 69892.197",
          "/PMSSM_set_2_LL_2_TuneCP2_13TeV-pythia8/RunIIFall17MiniAODv2-PUFall17Fast_GridpackScan_94X_mc2017_realistic_v15-v2/MINIAODSIM - CPU Time: 17037.596",
          "/PMSSM_set_2_prompt_1_TuneCP2_13TeV-pythia8/RunIIAutumn18MiniAOD-PUFall18Fast_GridpackScan_102X_upgrade2018_realistic_v15-v4/MINIAODSIM - CPU Time: 15396.829",
          "/EGamma/Run2018D-12Nov2019_UL2018-v4/MINIAOD - CPU Time: 9300.392",
          "Null - CPU Time: 1940074.206",
          "/EGamma/Run2018D-v1/RAW - CPU Time: 262771.892",
          "/SingleMuon/Run2018D-15Feb2022_UL2018-v1/AOD - CPU Time: 18780.260",
          "/ExpressCosmics/Commissioning2022-Express-v1/FEVT - CPU Time: 18372.974",
          "/EGamma/Run2018D-12Nov2019_UL2018-v4/MINIAOD - CPU Time: 13712.946",
          "Null - CPU Time: 1640172.343",
          "/EGamma/Run2018D-v1/RAW - CPU Time: 20160.249",
          "/PMSSM_set_2_prompt_1_TuneCP2_13TeV-pythia8/RunIIFall17MiniAODv2-PUFall17Fast_GridpackScan_94X_mc2017_realistic_v15-v2/MINIAODSIM - CPU Time: 13416.153",
          "/EGamma/Run2018D-12Nov2019_UL2018-v4/MINIAOD - CPU Time: 11940.400",
          "/SingleMuon/Run2018D-15Feb2022_UL2018-v1/AOD - CPU Time: 7905.396"
         ],
         "labels": [
          "May 1st Week",
          "30/04",
          "01/05",
          "02/05",
          "03/05",
          "04/05",
          "05/05",
          "06/05",
          "07/05",
          "30 - Top1",
          "30 - Top2",
          "30 - Top3",
          "30 - Top4",
          "30 - Top5",
          "01 - Top1",
          "01 - Top2",
          "01 - Top3",
          "01 - Top4",
          "01 - Top5",
          "02 - Top1",
          "02 - Top2",
          "02 - Top3",
          "02 - Top4",
          "02 - Top5",
          "03 - Top1",
          "03 - Top2",
          "03 - Top3",
          "03 - Top4",
          "03 - Top5",
          "04 - Top1",
          "04 - Top2",
          "04 - Top3",
          "04 - Top4",
          "04 - Top5",
          "05 - Top1",
          "05 - Top2",
          "05 - Top3",
          "05 - Top4",
          "05 - Top5",
          "06 - Top1",
          "06 - Top2",
          "06 - Top3",
          "06 - Top4",
          "06 - Top5",
          "07 - Top1",
          "07 - Top2",
          "07 - Top3",
          "07 - Top4",
          "07 - Top5"
         ],
         "name": "",
         "parents": [
          "",
          "May 1st Week",
          "May 1st Week",
          "May 1st Week",
          "May 1st Week",
          "May 1st Week",
          "May 1st Week",
          "May 1st Week",
          "May 1st Week",
          "30/04",
          "30/04",
          "30/04",
          "30/04",
          "30/04",
          "01/05",
          "01/05",
          "01/05",
          "01/05",
          "01/05",
          "02/05",
          "02/05",
          "02/05",
          "02/05",
          "02/05",
          "03/05",
          "03/05",
          "03/05",
          "03/05",
          "03/05",
          "04/05",
          "04/05",
          "04/05",
          "04/05",
          "04/05",
          "05/05",
          "05/05",
          "05/05",
          "05/05",
          "05/05",
          "06/05",
          "06/05",
          "06/05",
          "06/05",
          "06/05",
          "07/05",
          "07/05",
          "07/05",
          "07/05",
          "07/05"
         ],
         "type": "sunburst",
         "values": [
          17230754.609444443,
          570767.4969444439,
          3237665.5605555526,
          2405833.891111112,
          2780124.6286111106,
          1640770.8308333335,
          1856863.838611111,
          2425978.531666666,
          2002801.1166666658,
          525436.4152777776,
          8444.535,
          7913.049722222222,
          5497.0647222222215,
          4336.977777777776,
          2391008.1249999995,
          35902.691388888896,
          33715.24527777778,
          28417.583888888887,
          22874.27722222223,
          1914446.3705555557,
          30692.126944444448,
          27810.1225,
          22828.949722222223,
          22618.157222222228,
          2324922.7091666684,
          61326.85555555555,
          32056.296666666654,
          24778.9288888889,
          23074.572222222214,
          1220947.469444445,
          22284.81305555556,
          18760.713888888895,
          16905.316944444443,
          11880.74472222222,
          1361493.0799999994,
          69892.19666666664,
          17037.59638888889,
          15396.828611111123,
          9300.392222222219,
          1940074.2055555556,
          262771.8916666667,
          18780.260277777776,
          18372.974444444437,
          13712.94555555555,
          1640172.3425,
          20160.249444444456,
          13416.15277777778,
          11940.400277777779,
          7905.396388888889
         ]
        }
       ],
       "layout": {
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"785df3b4-ea60-4dee-9457-daa4a2a80fc9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"785df3b4-ea60-4dee-9457-daa4a2a80fc9\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '785df3b4-ea60-4dee-9457-daa4a2a80fc9',\n",
       "                        [{\"branchvalues\": \"total\", \"hovertemplate\": [\"May 1st Week - CPU Time: 17230754.609\", \"30/04 - CPU Time: 570767.497\", \"01/05 - CPU Time: 3237665.561\", \"02/05 - CPU Time: 2405833.891\", \"03/05 - CPU Time: 2780124.629\", \"04/05 - CPU Time: 1640770.831\", \"05/05 - CPU Time: 1856863.839\", \"06/05 - CPU Time: 2425978.532\", \"07/05 - CPU Time: 2002801.117\", \"Null - CPU Time: 525436.415\", \"/TTJets_TuneCP5_13TeV-amcatnloFXFX-pythia8/RunIISummer20UL17MiniAOD-106X_mc2017_realistic_v6-v2/MINIAODSIM - CPU Time: 8444.535\", \"/MuOnia/Run2018A-v1/RAW - CPU Time: 7913.050\", \"/Charmonium/Run2018A-v1/RAW - CPU Time: 5497.065\", \"/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL17MiniAOD-106X_mc2017_realistic_v6-v2/MINIAODSIM - CPU Time: 4336.978\", \"Null - CPU Time: 2391008.125\", \"/MuOnia/Run2018A-v1/RAW - CPU Time: 35902.691\", \"/Tau/Run2018A-v1/RAW - CPU Time: 33715.245\", \"/Tau/Run2018B-v1/RAW - CPU Time: 28417.584\", \"/Tau/Run2018C-v1/RAW - CPU Time: 22874.277\", \"Null - CPU Time: 1914446.371\", \"/EGamma/Run2018C-v1/RAW - CPU Time: 30692.127\", \"/Tau/Run2018A-v1/RAW - CPU Time: 27810.123\", \"/Charmonium/Run2018D-v1/RAW - CPU Time: 22828.950\", \"/SingleMuon/Run2018A-UL2018_MiniAODv2-v3/MINIAOD - CPU Time: 22618.157\", \"Null - CPU Time: 2324922.709\", \"/EGamma/Run2018C-v1/RAW - CPU Time: 61326.856\", \"/EGamma/Run2018D-12Nov2019_UL2018-v4/MINIAOD - CPU Time: 32056.297\", \"/Tau/Run2018A-v1/RAW - CPU Time: 24778.929\", \"/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18MiniAODv2-106X_upgrade2018_realistic_v16_L1v1-v2/MINIAODSIM - CPU Time: 23074.572\", \"Null - CPU Time: 1220947.469\", \"/PMSSM_set_2_LL_2_TuneCP2_13TeV-pythia8/RunIIFall17MiniAODv2-PUFall17Fast_GridpackScan_94X_mc2017_realistic_v15-v2/MINIAODSIM - CPU Time: 22284.813\", \"/EGamma/Run2018D-12Nov2019_UL2018-v4/MINIAOD - CPU Time: 18760.714\", \"/EGamma/Run2018C-v1/RAW - CPU Time: 16905.317\", \"/Tau/Run2018A-v1/RAW - CPU Time: 11880.745\", \"Null - CPU Time: 1361493.080\", \"/EGamma/Run2018D-v1/RAW - CPU Time: 69892.197\", \"/PMSSM_set_2_LL_2_TuneCP2_13TeV-pythia8/RunIIFall17MiniAODv2-PUFall17Fast_GridpackScan_94X_mc2017_realistic_v15-v2/MINIAODSIM - CPU Time: 17037.596\", \"/PMSSM_set_2_prompt_1_TuneCP2_13TeV-pythia8/RunIIAutumn18MiniAOD-PUFall18Fast_GridpackScan_102X_upgrade2018_realistic_v15-v4/MINIAODSIM - CPU Time: 15396.829\", \"/EGamma/Run2018D-12Nov2019_UL2018-v4/MINIAOD - CPU Time: 9300.392\", \"Null - CPU Time: 1940074.206\", \"/EGamma/Run2018D-v1/RAW - CPU Time: 262771.892\", \"/SingleMuon/Run2018D-15Feb2022_UL2018-v1/AOD - CPU Time: 18780.260\", \"/ExpressCosmics/Commissioning2022-Express-v1/FEVT - CPU Time: 18372.974\", \"/EGamma/Run2018D-12Nov2019_UL2018-v4/MINIAOD - CPU Time: 13712.946\", \"Null - CPU Time: 1640172.343\", \"/EGamma/Run2018D-v1/RAW - CPU Time: 20160.249\", \"/PMSSM_set_2_prompt_1_TuneCP2_13TeV-pythia8/RunIIFall17MiniAODv2-PUFall17Fast_GridpackScan_94X_mc2017_realistic_v15-v2/MINIAODSIM - CPU Time: 13416.153\", \"/EGamma/Run2018D-12Nov2019_UL2018-v4/MINIAOD - CPU Time: 11940.400\", \"/SingleMuon/Run2018D-15Feb2022_UL2018-v1/AOD - CPU Time: 7905.396\"], \"labels\": [\"May 1st Week\", \"30/04\", \"01/05\", \"02/05\", \"03/05\", \"04/05\", \"05/05\", \"06/05\", \"07/05\", \"30 - Top1\", \"30 - Top2\", \"30 - Top3\", \"30 - Top4\", \"30 - Top5\", \"01 - Top1\", \"01 - Top2\", \"01 - Top3\", \"01 - Top4\", \"01 - Top5\", \"02 - Top1\", \"02 - Top2\", \"02 - Top3\", \"02 - Top4\", \"02 - Top5\", \"03 - Top1\", \"03 - Top2\", \"03 - Top3\", \"03 - Top4\", \"03 - Top5\", \"04 - Top1\", \"04 - Top2\", \"04 - Top3\", \"04 - Top4\", \"04 - Top5\", \"05 - Top1\", \"05 - Top2\", \"05 - Top3\", \"05 - Top4\", \"05 - Top5\", \"06 - Top1\", \"06 - Top2\", \"06 - Top3\", \"06 - Top4\", \"06 - Top5\", \"07 - Top1\", \"07 - Top2\", \"07 - Top3\", \"07 - Top4\", \"07 - Top5\"], \"name\": \"\", \"parents\": [\"\", \"May 1st Week\", \"May 1st Week\", \"May 1st Week\", \"May 1st Week\", \"May 1st Week\", \"May 1st Week\", \"May 1st Week\", \"May 1st Week\", \"30/04\", \"30/04\", \"30/04\", \"30/04\", \"30/04\", \"01/05\", \"01/05\", \"01/05\", \"01/05\", \"01/05\", \"02/05\", \"02/05\", \"02/05\", \"02/05\", \"02/05\", \"03/05\", \"03/05\", \"03/05\", \"03/05\", \"03/05\", \"04/05\", \"04/05\", \"04/05\", \"04/05\", \"04/05\", \"05/05\", \"05/05\", \"05/05\", \"05/05\", \"05/05\", \"06/05\", \"06/05\", \"06/05\", \"06/05\", \"06/05\", \"07/05\", \"07/05\", \"07/05\", \"07/05\", \"07/05\"], \"type\": \"sunburst\", \"values\": [17230754.609444443, 570767.4969444439, 3237665.5605555526, 2405833.891111112, 2780124.6286111106, 1640770.8308333335, 1856863.838611111, 2425978.531666666, 2002801.1166666658, 525436.4152777776, 8444.535, 7913.049722222222, 5497.0647222222215, 4336.977777777776, 2391008.1249999995, 35902.691388888896, 33715.24527777778, 28417.583888888887, 22874.27722222223, 1914446.3705555557, 30692.126944444448, 27810.1225, 22828.949722222223, 22618.157222222228, 2324922.7091666684, 61326.85555555555, 32056.296666666654, 24778.9288888889, 23074.572222222214, 1220947.469444445, 22284.81305555556, 18760.713888888895, 16905.316944444443, 11880.74472222222, 1361493.0799999994, 69892.19666666664, 17037.59638888889, 15396.828611111123, 9300.392222222219, 1940074.2055555556, 262771.8916666667, 18780.260277777776, 18372.974444444437, 13712.94555555555, 1640172.3425, 20160.249444444456, 13416.15277777778, 11940.400277777779, 7905.396388888889]}],\n",
       "                        {\"margin\": {\"b\": 0, \"l\": 0, \"r\": 0, \"t\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('785df3b4-ea60-4dee-9457-daa4a2a80fc9');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig =go.Figure(go.Sunburst(\n",
    "    labels=Labels,\n",
    "    parents=Parents,\n",
    "    values=Values,\n",
    "    hovertemplate=Hover,\n",
    "    name=\"\",\n",
    "    branchvalues=\"total\"\n",
    "))\n",
    "fig.update_layout(margin = dict(t=0, l=0, r=0, b=0))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b783d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "sparkconnect": {
   "bundled_options": [],
   "list_of_options": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
