{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54dae579",
   "metadata": {},
   "source": [
    "written by: Nutchaya Phumekham, Aug 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0643d062",
   "metadata": {},
   "source": [
    "# DataFrame of DESIRED_CMSDataset and CRAB_DataBlock accessed in the specific times for CMS_SubmissionTool==CRAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6626200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    _to_dict,\n",
    "    _donut,\n",
    "    _pie,\n",
    "    _line_graph,\n",
    "    _other_fields,\n",
    "    _exitcode_info,\n",
    "    _better_label\n",
    ")\n",
    "from datetime import datetime, date, timedelta\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    lit,\n",
    "    when,\n",
    "    sum as _sum,\n",
    "    max as _max,\n",
    "    min as _min,\n",
    "    count as _count,\n",
    "    first,\n",
    "    date_format,\n",
    "    from_unixtime,\n",
    "    to_date,\n",
    "    countDistinct\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    LongType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    DoubleType,\n",
    "    IntegerType,\n",
    ")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b9bb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_schema():\n",
    "    return StructType(\n",
    "        [\n",
    "            StructField(\n",
    "                \"data\",\n",
    "                StructType(\n",
    "                    [\n",
    "                        StructField(\"RecordTime\", LongType(), nullable=False),\n",
    "                        StructField(\"DESIRED_CMSDataset\", StringType(), nullable=True),\n",
    "                        StructField(\"GlobalJobId\", StringType(), nullable=False),\n",
    "                        StructField(\"CMS_SubmissionTool\", StringType(), nullable=True),\n",
    "                        StructField(\"CRAB_DataBlock\", StringType(), nullable=True),\n",
    "                        StructField(\"CMSPrimaryDataTier\", StringType(), nullable=True),\n",
    "                        StructField(\"CRAB_Workflow\", StringType(), nullable=True)\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe309f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_files(start_date, end_date, spark, base):\n",
    "    st_date = start_date - timedelta(days=3)\n",
    "    ed_date = end_date + timedelta(days=3)\n",
    "    days = (ed_date - st_date).days\n",
    "    pre_candidate_files = [\n",
    "        \"{base}/{day}{{,.tmp}}\".format(\n",
    "            base=base, day=(st_date + timedelta(days=i)).strftime(\"%Y/%m/%d\")\n",
    "        )\n",
    "        for i in range(0, days)\n",
    "    ]\n",
    "    sc = spark.sparkContext\n",
    "    candidate_files = [\n",
    "        f\"{base}/{(st_date + timedelta(days=i)).strftime('%Y/%m/%d')}\"\n",
    "        for i in range(0, days)\n",
    "    ]\n",
    "    FileSystem = sc._gateway.jvm.org.apache.hadoop.fs.FileSystem\n",
    "    URI = sc._gateway.jvm.java.net.URI\n",
    "    Path = sc._gateway.jvm.org.apache.hadoop.fs.Path\n",
    "    fs = FileSystem.get(URI(\"hdfs:///\"), sc._jsc.hadoopConfiguration())\n",
    "    candidate_files = [url for url in candidate_files if fs.globStatus(Path(url))]\n",
    "    return candidate_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f68f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DEFAULT_HDFS_FOLDER = \"/project/monitoring/archive/condor/raw/metric\"\n",
    "HDFS_DBS_FILES = '/project/awg/cms/CMS_DBS3_PROD_GLOBAL/current/FILES/part-m-00000'\n",
    "HDFS_DBS_DATASETS = '/project/awg/cms/CMS_DBS3_PROD_GLOBAL/current/DATASETS/part-m-00000'\n",
    "HDFS_DFS_BLOCKS = '/project/awg/cms/CMS_DBS3_PROD_GLOBAL/current/BLOCKS/part-m-00000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea7f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = _get_schema()\n",
    "start_date = datetime(2022, 5, 1)\n",
    "end_date = datetime(2022, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1437de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/project/monitoring/archive/condor/raw/metric/2022/04/28',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/04/29',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/04/30',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/05/01',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/05/02',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/05/03',\n",
       " '/project/monitoring/archive/condor/raw/metric/2022/05/04']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_candidate_files(start_date, end_date, spark, base=_DEFAULT_HDFS_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cea47e",
   "metadata": {},
   "source": [
    "### Raw DF is filtered for CMS_SubmissionTool == 'CRAB'\n",
    "- start_date = datetime(2022, 5, 1)\n",
    "- end_date = datetime(2022, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1343bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = (\n",
    "        spark.read.option(\"basePath\", _DEFAULT_HDFS_FOLDER)\n",
    "        .json(\n",
    "            get_candidate_files(start_date, end_date, spark, base=_DEFAULT_HDFS_FOLDER),\n",
    "            schema=schema,\n",
    "        ).select(\"data.*\")\n",
    "        .filter(\n",
    "            f\"\"\"CMS_SubmissionTool == 'CRAB'\n",
    "          AND CMSPrimaryDataTier != 'Unknown'\n",
    "          AND CRAB_DataBlock IS NOT NULL\n",
    "          AND RecordTime >= {start_date.timestamp() * 1000}\n",
    "          AND RecordTime < {end_date.timestamp() * 1000}\n",
    "          \"\"\"\n",
    "        )\n",
    "        .drop_duplicates([\"GlobalJobId\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3182dd",
   "metadata": {},
   "source": [
    "### d_size_df - dataset size and b_size_df - block size\n",
    "- HDFS_DBS_FILES = '/project/awg/cms/CMS_DBS3_PROD_GLOBAL/current/FILES/part-m-00000'\n",
    "- HDFS_DBS_DATASETS = '/project/awg/cms/CMS_DBS3_PROD_GLOBAL/current/DATASETS/part-m-00000'\n",
    "- HDFS_DFS_BLOCKS = '/project/awg/cms/CMS_DBS3_PROD_GLOBAL/current/BLOCKS/part-m-00000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a65c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CMSSpark.src.python.CMSSpark import schemas as cms_schemas\n",
    "csvreader = spark.read.format('csv') \\\n",
    "        .option('nullValue', 'null') \\\n",
    "        .option('mode', 'FAILFAST')\n",
    "dbs_files = csvreader.schema(cms_schemas.schema_files()) \\\n",
    "        .load(HDFS_DBS_FILES) \\\n",
    "        .select(['f_file_size', 'f_block_id', 'f_dataset_id'])\\\n",
    "        .withColumnRenamed('f_block_id', 'BLOCK_ID')\\\n",
    "        .withColumnRenamed('f_dataset_id', 'DATASET_ID')\n",
    "        \n",
    "dbs_datasets = csvreader.schema(cms_schemas.schema_datasets()) \\\n",
    "        .load(HDFS_DBS_DATASETS) \\\n",
    "        .select(['d_dataset_id', 'd_dataset']).withColumnRenamed('d_dataset_id', 'DATASET_ID')\n",
    "\n",
    "d_size_df = dbs_datasets.join(dbs_files, ['DATASET_ID'], how='left') \\\n",
    "        .groupby('d_dataset') \\\n",
    "        .agg(\n",
    "            _sum('f_file_size').alias('dataset_size'))\n",
    "    \n",
    "b_size_df = csvreader.schema(cms_schemas.schema_blocks()) \\\n",
    "    .load(HDFS_DFS_BLOCKS) \\\n",
    "    .select(['b_block_name', 'b_block_size']).withColumnRenamed('b_block_size', 'block_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e70f7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordTime: long (nullable = true)\n",
      " |-- DESIRED_CMSDataset: string (nullable = true)\n",
      " |-- GlobalJobId: string (nullable = true)\n",
      " |-- CMS_SubmissionTool: string (nullable = true)\n",
      " |-- CRAB_DataBlock: string (nullable = true)\n",
      " |-- CMSPrimaryDataTier: string (nullable = true)\n",
      " |-- CRAB_Workflow: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d510658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- d_dataset: string (nullable = true)\n",
      " |-- dataset_size: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_size_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adec9696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- b_block_name: string (nullable = true)\n",
      " |-- block_size: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b_size_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cf7856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a687c1c",
   "metadata": {},
   "source": [
    "### Table1: Dataset size of datasets that appear in raw_df\n",
    "raw_df.DESIRED_CMSDataset == d_size_df.d_dataset AND drop_duplicates('DESIRED_CMSDataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d624ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets accessed withing specific time range without considering diff user/job/etc\n",
    "datasets = raw_df.select(['CMSPrimaryDataTier', 'DESIRED_CMSDataset']).drop_duplicates(['DESIRED_CMSDataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a84bc912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+\n",
      "|summary|CMSPrimaryDataTier|  DESIRED_CMSDataset|\n",
      "+-------+------------------+--------------------+\n",
      "|  count|             12549|               12548|\n",
      "|   mean|              null|                null|\n",
      "| stddev|              null|                null|\n",
      "|    min|          ALCARECO|/ADDGravToGG_NegI...|\n",
      "|    25%|              null|                null|\n",
      "|    50%|              null|                null|\n",
      "|    75%|              null|                null|\n",
      "|    max|           Unknown|/ttbb_4FS_ckm_amc...|\n",
      "+-------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc7bda8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dateset_size = datasets.join(d_size_df, datasets.DESIRED_CMSDataset==d_size_df.d_dataset)\\\n",
    "                        .select(['CMSPrimaryDataTier', 'DESIRED_CMSDataset', 'dataset_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac89e1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/08/10 14:58:29 ERROR TransportClient: Failed to send RPC RPC 4664192354841823182 to /188.185.8.32:32929: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 ERROR TransportClient: Failed to send RPC RPC 8815252948923697784 to /188.185.8.32:27066: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 1 from block manager BlockManagerId(47, ithdp1109.cern.ch, 5102, None)\n",
      "java.io.IOException: Failed to send RPC RPC 4664192354841823182 to /188.185.8.32:32929: io.netty.channel.StacklessClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:392)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:369)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:1017)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:878)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 1 from block manager BlockManagerId(57, ithdp4024.cern.ch, 5101, None)\n",
      "java.io.IOException: Failed to send RPC RPC 8815252948923697784 to /188.185.8.32:27066: io.netty.channel.StacklessClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:392)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:369)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:1017)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:878)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 ERROR TransportClient: Failed to send RPC RPC 9077930657426012300 to /188.185.8.32:55031: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 1 from block manager BlockManagerId(53, ithdp1109.cern.ch, 5101, None)\n",
      "java.io.IOException: Failed to send RPC RPC 9077930657426012300 to /188.185.8.32:55031: io.netty.channel.StacklessClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:392)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:369)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:1017)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:878)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 ERROR TransportClient: Failed to send RPC RPC 9119143091000604909 to /188.185.8.32:32929: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 ERROR TransportClient: Failed to send RPC RPC 8220524019923264108 to /188.185.8.32:27066: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 WARN BlockManagerMasterEndpoint: Error trying to remove shuffle 0 from block manager BlockManagerId(47, ithdp1109.cern.ch, 5102, None)\n",
      "java.io.IOException: Failed to send RPC RPC 9119143091000604909 to /188.185.8.32:32929: io.netty.channel.StacklessClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:392)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:369)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:1017)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:878)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 ERROR TransportClient: Failed to send RPC RPC 7344430599054907343 to /188.185.8.32:32929: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 ERROR TransportClient: Failed to send RPC RPC 7976185234341615077 to /188.185.8.32:55031: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 WARN BlockManagerMasterEndpoint: Error trying to remove shuffle 0 from block manager BlockManagerId(57, ithdp4024.cern.ch, 5101, None)\n",
      "java.io.IOException: Failed to send RPC RPC 8220524019923264108 to /188.185.8.32:27066: io.netty.channel.StacklessClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:392)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:369)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:1017)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:878)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 ERROR TransportClient: Failed to send RPC RPC 8367491382608766354 to /188.185.8.32:27066: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 WARN BlockManagerMasterEndpoint: Error trying to remove shuffle 0 from block manager BlockManagerId(53, ithdp1109.cern.ch, 5101, None)\n",
      "java.io.IOException: Failed to send RPC RPC 7976185234341615077 to /188.185.8.32:55031: io.netty.channel.StacklessClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:392)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:369)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:1017)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:878)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 0 from block manager BlockManagerId(47, ithdp1109.cern.ch, 5102, None)\n",
      "java.io.IOException: Failed to send RPC RPC 7344430599054907343 to /188.185.8.32:32929: io.netty.channel.StacklessClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:392)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:369)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:1017)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:878)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 ERROR TransportClient: Failed to send RPC RPC 7084804577812122363 to /188.185.8.32:55031: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 0 from block manager BlockManagerId(57, ithdp4024.cern.ch, 5101, None)\n",
      "java.io.IOException: Failed to send RPC RPC 8367491382608766354 to /188.185.8.32:27066: io.netty.channel.StacklessClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:392)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:369)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:1017)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:878)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 0 from block manager BlockManagerId(53, ithdp1109.cern.ch, 5101, None)\n",
      "java.io.IOException: Failed to send RPC RPC 7084804577812122363 to /188.185.8.32:55031: io.netty.channel.StacklessClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:392)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:369)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:1017)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:878)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/08/10 14:58:29 WARN BlockManagerMaster: Failed to remove broadcast 0 with removeFromMaster = true - org.apache.spark.SparkException: Could not find BlockManagerEndpoint1.\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postRemoteMessage(Dispatcher.scala:136)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:684)\n",
      "\tat org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:163)\n",
      "\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n",
      "\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "java.lang.RuntimeException: org.apache.spark.SparkException: Could not find BlockManagerEndpoint1.\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postRemoteMessage(Dispatcher.scala:136)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:684)\n",
      "\tat org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:163)\n",
      "\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n",
      "\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:209)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n",
      "\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "22/08/10 14:58:29 ERROR ContextCleaner: Error cleaning broadcast 0\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeBroadcast(BlockManagerMaster.scala:194)\n",
      "\tat org.apache.spark.broadcast.TorrentBroadcast$.unpersist(TorrentBroadcast.scala:351)\n",
      "\tat org.apache.spark.broadcast.TorrentBroadcastFactory.unbroadcast(TorrentBroadcastFactory.scala:45)\n",
      "\tat org.apache.spark.broadcast.BroadcastManager.unbroadcast(BroadcastManager.scala:78)\n",
      "\tat org.apache.spark.ContextCleaner.doCleanupBroadcast(ContextCleaner.scala:254)\n",
      "\tat org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:204)\n",
      "\tat org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195)\n",
      "\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1404)\n",
      "\tat org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189)\n",
      "\tat org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79)\n",
      "Caused by: java.lang.RuntimeException: org.apache.spark.SparkException: Could not find BlockManagerEndpoint1.\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postRemoteMessage(Dispatcher.scala:136)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:684)\n",
      "\tat org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:163)\n",
      "\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n",
      "\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:209)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n",
      "\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n",
      "\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "|CMSPrimaryDataTier|DESIRED_CMSDataset                                                                                                                                     |dataset_size     |\n",
      "+------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "|MINIAODSIM        |/BulkGravToWWToWhadWhad_narrow_M-4500_TuneCP5_13TeV-madgraph-pythia/RunIISummer20UL16MiniAODAPV-106X_mcRun2_asymptotic_preVFP_v8-v2/MINIAODSIM         |1.1489723122E10  |\n",
      "|MINIAODSIM        |/BulkGravToZZToZhadZhad_narrow_M-600_TuneCP5_13TeV-madgraph-pythia/RunIISummer20UL17MiniAODv2-106X_mc2017_realistic_v9-v2/MINIAODSIM                   |1.8172329256E10  |\n",
      "|MINIAODSIM        |/BulkGravTohhTohVVhbb_narrow_M-1400_TuneCP5_13TeV-madgraph-pythia8/RunIIFall17MiniAODv2-PU2017_12Apr2018_94X_mc2017_realistic_v14-v1/MINIAODSIM        |2.4958794204E10  |\n",
      "|MINIAODSIM        |/ChargedHiggs_HplusTB_HplusToTB_M-1500_13TeV_amcatnlo_pythia8/RunIISummer16MiniAODv3-PUMoriond17_94X_mcRun2_asymptotic_v3-v2/MINIAODSIM                |9.4326821552E10  |\n",
      "|MINIAODSIM        |/DYJetsToLL_M-50_TuneCP5_13TeV-madgraphMLM-pythia8/RunIISummer20UL16MiniAODAPVv2-106X_mcRun2_asymptotic_preVFP_v11-v1/MINIAODSIM                       |3.578983108085E12|\n",
      "|MINIAOD           |/DoubleMuon/Run2017B-UL2017_MiniAODv2-v1/MINIAOD                                                                                                       |4.6295383912E11  |\n",
      "|MINIAODSIM        |/EWKZ2Jets_ZToNuNu_M-50_TuneCP5_withDipoleRecoil_13TeV-madgraph-pythia8/RunIISummer20UL17MiniAOD-106X_mc2017_realistic_v6-v2/MINIAODSIM                |1.4651907425E11  |\n",
      "|MINIAODSIM        |/GluGluHToTauTau_M125_13TeV_powheg_pythia8/RunIISummer16MiniAODv3-PUMoriond17_94X_mcRun2_asymptotic_v3-v2/MINIAODSIM                                   |4.6133877985E10  |\n",
      "|MINIAODSIM        |/GluGluToBulkGravitonToHHTo4B_M-8000_narrow_TuneCP5_13TeV-madgraph-pythia8/RunIISummer20UL18MiniAODv2-106X_upgrade2018_realistic_v16_L1v1-v2/MINIAODSIM|2.5871545411E10  |\n",
      "|MINIAODSIM        |/GluGluToRadionToHHTo2B2Tau_M-700_narrow_13TeV-madgraph_correctedcfg/RunIIFall17MiniAODv2-PU2017_12Apr2018_94X_mc2017_realistic_v14-v1/MINIAODSIM      |1.1214998225E10  |\n",
      "+------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateset_size.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f38c4e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+--------------------+\n",
      "|summary|CMSPrimaryDataTier|  DESIRED_CMSDataset|        dataset_size|\n",
      "+-------+------------------+--------------------+--------------------+\n",
      "|  count|             10819|               10819|               10819|\n",
      "|   mean|              null|                null|2.308864295416406...|\n",
      "| stddev|              null|                null|1.350402476414188E13|\n",
      "|    min|          ALCARECO|/ADDGravToGG_NegI...|         7.7320687E7|\n",
      "|    25%|              null|                null|       6.290462739E9|\n",
      "|    50%|              null|                null|     2.5367147132E10|\n",
      "|    75%|              null|                null|    4.99981753797E11|\n",
      "|    max|              USER|/ttbb_4FS_ckm_amc...| 5.16713993514068E14|\n",
      "+-------+------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateset_size.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea31d6e6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/08/10 15:33:12 WARN TaskSetManager: Lost task 9.0 in stage 138.0 (TID 9167) (ithdp5005.cern.ch executor 170): FetchFailed(BlockManagerId(201, ithdp5005.cern.ch, 7337, None), shuffleId=39, mapIndex=388, mapId=388, reduceId=9, message=\n",
      "org.apache.spark.shuffle.FetchFailedException: Block shuffle_39_388_9 is corrupted but the cause is unknown\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.tryOrFetchFailedException(ShuffleBlockFetcherIterator.scala:1319)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.read(ShuffleBlockFetcherIterator.scala:1299)\n",
      "\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n",
      "\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n",
      "\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\n",
      "\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2$$anon$3.readSize(UnsafeRowSerializer.scala:113)\n",
      "\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2$$anon$3.<init>(UnsafeRowSerializer.scala:120)\n",
      "\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2.asKeyValueIterator(UnsafeRowSerializer.scala:110)\n",
      "\tat org.apache.spark.shuffle.BlockStoreShuffleReader.$anonfun$read$2(BlockStoreShuffleReader.scala:98)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.smj_findNextJoinRows_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.agg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.io.IOException: Stream is corrupted\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:250)\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.read(LZ4BlockInputStream.java:157)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.$anonfun$read$3(ShuffleBlockFetcherIterator.scala:1299)\n",
      "\tat scala.runtime.java8.JFunction0$mcI$sp.apply(JFunction0$mcI$sp.java:23)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.tryOrFetchFailedException(ShuffleBlockFetcherIterator.scala:1310)\n",
      "\t... 35 more\n",
      "Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 9831 of input buffer\n",
      "\tat net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:245)\n",
      "\t... 39 more\n",
      "\n",
      ")\n",
      "22/08/10 15:33:19 WARN TaskSetManager: Lost task 4.0 in stage 138.1 (TID 9231) (ithdp5005.cern.ch executor 201): FetchFailed(BlockManagerId(201, ithdp5005.cern.ch, 5105, None), shuffleId=39, mapIndex=388, mapId=388, reduceId=9, message=\n",
      "org.apache.spark.shuffle.FetchFailedException: Block shuffle_39_388_9 is corrupted due to DISK_ISSUE\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.tryOrFetchFailedException(ShuffleBlockFetcherIterator.scala:1319)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.read(ShuffleBlockFetcherIterator.scala:1299)\n",
      "\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n",
      "\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n",
      "\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\n",
      "\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2$$anon$3.readSize(UnsafeRowSerializer.scala:113)\n",
      "\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2$$anon$3.<init>(UnsafeRowSerializer.scala:120)\n",
      "\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2.asKeyValueIterator(UnsafeRowSerializer.scala:110)\n",
      "\tat org.apache.spark.shuffle.BlockStoreShuffleReader.$anonfun$read$2(BlockStoreShuffleReader.scala:98)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.smj_findNextJoinRows_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.agg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.io.IOException: Stream is corrupted\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:250)\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.read(LZ4BlockInputStream.java:157)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.$anonfun$read$3(ShuffleBlockFetcherIterator.scala:1299)\n",
      "\tat scala.runtime.java8.JFunction0$mcI$sp.apply(JFunction0$mcI$sp.java:23)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.tryOrFetchFailedException(ShuffleBlockFetcherIterator.scala:1310)\n",
      "\t... 35 more\n",
      "Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 9497 of input buffer\n",
      "\tat net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:245)\n",
      "\t... 39 more\n",
      "\n",
      ")\n",
      "22/08/10 15:34:44 WARN TaskSetManager: Lost task 21.0 in stage 146.0 (TID 9509) (ithdp5005.cern.ch executor 170): FetchFailed(BlockManagerId(201, ithdp5005.cern.ch, 7337, None), shuffleId=40, mapIndex=22, mapId=22, reduceId=126, message=\n",
      "org.apache.spark.shuffle.FetchFailedException: Block shuffle_40_22_126 is corrupted but the cause is unknown\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.tryOrFetchFailedException(ShuffleBlockFetcherIterator.scala:1319)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.read(ShuffleBlockFetcherIterator.scala:1299)\n",
      "\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n",
      "\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n",
      "\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\n",
      "\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2$$anon$3.readSize(UnsafeRowSerializer.scala:113)\n",
      "\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2$$anon$3.<init>(UnsafeRowSerializer.scala:120)\n",
      "\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2.asKeyValueIterator(UnsafeRowSerializer.scala:110)\n",
      "\tat org.apache.spark.shuffle.BlockStoreShuffleReader.$anonfun$read$2(BlockStoreShuffleReader.scala:98)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.agg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage12.smj_findNextJoinRows_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage12.agg_doAggregateWithoutKey_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage12.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.io.IOException: Stream is corrupted\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:250)\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.read(LZ4BlockInputStream.java:157)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.$anonfun$read$3(ShuffleBlockFetcherIterator.scala:1299)\n",
      "\tat scala.runtime.java8.JFunction0$mcI$sp.apply(JFunction0$mcI$sp.java:23)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.tryOrFetchFailedException(ShuffleBlockFetcherIterator.scala:1310)\n",
      "\t... 36 more\n",
      "Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 2498 of input buffer\n",
      "\tat net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:245)\n",
      "\t... 40 more\n",
      "\n",
      ")\n",
      "22/08/10 15:35:30 WARN TaskSetManager: Lost task 11.0 in stage 146.1 (TID 9566) (ithdp4022.cern.ch executor 204): FetchFailed(BlockManagerId(201, ithdp5005.cern.ch, 7337, None), shuffleId=40, mapIndex=22, mapId=22, reduceId=126, message=\n",
      "org.apache.spark.shuffle.FetchFailedException: Block shuffle_40_22_126 is corrupted but the cause is unknown\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.tryOrFetchFailedException(ShuffleBlockFetcherIterator.scala:1319)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.read(ShuffleBlockFetcherIterator.scala:1299)\n",
      "\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n",
      "\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n",
      "\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\n",
      "\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2$$anon$3.readSize(UnsafeRowSerializer.scala:113)\n",
      "\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2$$anon$3.<init>(UnsafeRowSerializer.scala:120)\n",
      "\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2.asKeyValueIterator(UnsafeRowSerializer.scala:110)\n",
      "\tat org.apache.spark.shuffle.BlockStoreShuffleReader.$anonfun$read$2(BlockStoreShuffleReader.scala:98)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.agg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage12.smj_findNextJoinRows_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage12.agg_doAggregateWithoutKey_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage12.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.io.IOException: Stream is corrupted\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:250)\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.read(LZ4BlockInputStream.java:157)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.$anonfun$read$3(ShuffleBlockFetcherIterator.scala:1299)\n",
      "\tat scala.runtime.java8.JFunction0$mcI$sp.apply(JFunction0$mcI$sp.java:23)\n",
      "\tat org.apache.spark.storage.BufferReleasingInputStream.tryOrFetchFailedException(ShuffleBlockFetcherIterator.scala:1310)\n",
      "\t... 36 more\n",
      "Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 2494 of input buffer\n",
      "\tat net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)\n",
      "\tat net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:245)\n",
      "\t... 40 more\n",
      "\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------+\n",
      "|CMSPrimaryDataTier|DESIRED_CMSDataset|dataset_size|\n",
      "+------------------+------------------+------------+\n",
      "|                 0|                 0|           0|\n",
      "+------------------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,isnan,when,count\n",
    "a = dateset_size.select([count(when(col(c).contains('None') | \\\n",
    "                            col(c).contains('NULL') | \\\n",
    "                            col(c).contains('null') | \\\n",
    "                            (col(c) == '' ) | \\\n",
    "                            col(c).isNull() | \\\n",
    "                            isnan(c), c \n",
    "                           )).alias(c)\n",
    "                    for c in dateset_size.columns])\n",
    "\n",
    "a.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c4a965",
   "metadata": {},
   "source": [
    "### Table2: Block size of blocks that appear in raw_df\n",
    "raw_df.CRAB_DataBlock == b_size_df.b_block_name AND drop_duplicates('CRAB_DataBlock')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "234282b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blocks accessed withing specific time range without considering diff user/job/etc\n",
    "from pyspark.sql import Window\n",
    "blocks = raw_df.withColumn(\"first_access\", _min('RecordTime').over(Window.partitionBy('CRAB_DataBlock')))\\\n",
    "            .withColumn(\"last_access\", _max('RecordTime').over(Window.partitionBy('CRAB_DataBlock')))\\\n",
    "            .select(['DESIRED_CMSDataset', 'CRAB_DataBlock', 'CRAB_Workflow', 'first_access', 'last_access'])\\\n",
    "            .drop_duplicates(['CRAB_DataBlock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea85f6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|summary|  DESIRED_CMSDataset|      CRAB_DataBlock|       CRAB_Workflow|        first_access|         last_access|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  count|               10485|               10486|               10487|               10487|               10487|\n",
      "|   mean|                null|                null|                null|1.651402187300848...|1.651415701606751...|\n",
      "| stddev|                null|                null|                null|2.2869054699137878E7| 1.897668727966448E7|\n",
      "|    min|/BPlusToJpsiK_pTh...|/BPlusToJpsiK_pTh...|200226_221614:esc...|       1651356000000|       1651356001000|\n",
      "|    25%|                null|                null|                null|       1651397762000|       1651403571000|\n",
      "|    50%|                null|                null|                null|       1651403518000|       1651409788000|\n",
      "|    75%|                null|                null|                null|       1651409287000|       1651438126000|\n",
      "|    max|/ttHTobb_M125_Tun...|  UserFilesFakeBlock|220501_211503:tva...|       1651442384000|       1651442399000|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blocks.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09487725",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = blocks.join(b_size_df, blocks.CRAB_DataBlock==b_size_df.b_block_name)\\\n",
    "                        .select(['DESIRED_CMSDataset', 'CRAB_DataBlock', 'block_size', 'CRAB_Workflow', 'first_access', 'last_access'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5110929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|summary|  DESIRED_CMSDataset|      CRAB_DataBlock|          block_size|       CRAB_Workflow|        first_access|         last_access|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  count|                9972|                9972|                9972|                9972|                9972|                9972|\n",
      "|   mean|                null|                null|4.863553386768151E10|                null|1.651401724591055E12|1.651415570126654...|\n",
      "| stddev|                null|                null|1.914416664348531...|                null| 2.354649470811847E7| 1.949631900440551E7|\n",
      "|    min|/BPlusToJpsiK_pTh...|/BPlusToJpsiK_pTh...|           2964934.0|201020_093216:anm...|       1651356000000|       1651356001000|\n",
      "|    25%|                null|                null|        3.59850916E8|                null|       1651397041000|       1651403405000|\n",
      "|    50%|                null|                null|       1.535503018E9|                null|       1651402939000|       1651409282000|\n",
      "|    75%|                null|                null|       9.687534635E9|                null|       1651409502000|       1651439176000|\n",
      "|    max|/ttHTobb_M125_Tun...|/ttHTobb_M125_Tun...|   2.274199381335E12|220501_211503:tva...|       1651442384000|       1651442399000|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "block_size.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a768e876",
   "metadata": {},
   "source": [
    "### Table3: Join the dataset and block tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "331b2519",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dateset_size.join(block_size, dateset_size.DESIRED_CMSDataset == block_size.DESIRED_CMSDataset)\\\n",
    "                .select([dateset_size.CMSPrimaryDataTier, dateset_size.DESIRED_CMSDataset, 'dataset_size', 'CRAB_DataBlock', 'block_size', 'CRAB_Workflow', 'first_access', 'last_access'])\\\n",
    "                .orderBy(col('dataset_size').desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0cd42fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------------------------------------------------------------------------------------------------------+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------------------------------------------------------------------------------------------------------+-------------+-------------+\n",
      "|CMSPrimaryDataTier|DESIRED_CMSDataset                                                                                                |dataset_size       |CRAB_DataBlock                                                                                                                                         |block_size       |CRAB_Workflow                                                                                            |first_access |last_access  |\n",
      "+------------------+------------------------------------------------------------------------------------------------------------------+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------------------------------------------------------------------------------------------------------+-------------+-------------+\n",
      "|AODSIM            |/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM|2.01098979361666E14|/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#61e2b023-5f17-4dea-a170-649029f7750b|7.59833006954E11 |220501_211346:tvami_crab_Analysis_2018_TTToSemiLeptonic_wProbQ_CodeV19p1_v1                              |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM|2.01098979361666E14|/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#37c3ebb1-e4cf-48fc-be4b-09dc4880e918|2.20923894588E11 |220501_211346:tvami_crab_Analysis_2018_TTToSemiLeptonic_wProbQ_CodeV19p1_v1                              |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM|2.01098979361666E14|/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#6d19eeed-94d7-4ff8-8fe9-03fdbee68f85|8.22162527E8     |220501_211346:tvami_crab_Analysis_2018_TTToSemiLeptonic_wProbQ_CodeV19p1_v1                              |1651440241000|1651442136000|\n",
      "|AODSIM            |/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM|2.01098979361666E14|/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#aa77374a-ca40-4ff6-bb88-57d3d938ce56|8.20088476561E11 |220501_211346:tvami_crab_Analysis_2018_TTToSemiLeptonic_wProbQ_CodeV19p1_v1                              |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM|2.01098979361666E14|/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#a9649d7a-3902-41c8-9113-1c7b66ccde4c|3.1697052869E10  |220501_211346:tvami_crab_Analysis_2018_TTToSemiLeptonic_wProbQ_CodeV19p1_v1                              |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM|2.01098979361666E14|/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#ad25f359-fe52-49eb-8f8b-35008af18d50|2.017740712041E12|220501_211346:tvami_crab_Analysis_2018_TTToSemiLeptonic_wProbQ_CodeV19p1_v1                              |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM|2.01098979361666E14|/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#8aa8c56c-2700-4ab0-8a4a-1a2c5d6a6338|3.22430942576E11 |220501_211346:tvami_crab_Analysis_2018_TTToSemiLeptonic_wProbQ_CodeV19p1_v1                              |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM|2.01098979361666E14|/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#52bf3523-6cb4-41be-9127-bdb6fc30f198|1.3819626771E10  |220501_211346:tvami_crab_Analysis_2018_TTToSemiLeptonic_wProbQ_CodeV19p1_v1                              |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM|2.01098979361666E14|/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#036ba94b-0f54-40c9-82f3-22b2d94ee44d|1.01549042131E11 |220501_211346:tvami_crab_Analysis_2018_TTToSemiLeptonic_wProbQ_CodeV19p1_v1                              |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM|2.01098979361666E14|/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#ebe32aaf-73e1-400a-baee-d7891f68ae91|8.1265447E8      |220501_211346:tvami_crab_Analysis_2018_TTToSemiLeptonic_wProbQ_CodeV19p1_v1                              |1651440241000|1651442267000|\n",
      "|AODSIM            |/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM|2.01098979361666E14|/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#11d252ca-c669-4dc5-9a33-9cde08c9e420|8.137632095E9    |220501_211346:tvami_crab_Analysis_2018_TTToSemiLeptonic_wProbQ_CodeV19p1_v1                              |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM|2.01098979361666E14|/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#68d82fa6-ef1a-4781-b1dc-3c7d033da9e7|1.625782638E9    |220501_211346:tvami_crab_Analysis_2018_TTToSemiLeptonic_wProbQ_CodeV19p1_v1                              |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM|2.01098979361666E14|/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#44165f60-c8f9-42e6-ab43-bc767f601f82|3.009347217E10   |220501_211346:tvami_crab_Analysis_2018_TTToSemiLeptonic_wProbQ_CodeV19p1_v1                              |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM|2.01098979361666E14|/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#8e6a90c2-f981-4beb-92d5-a2e6f0124728|3.86824734903E11 |220501_211346:tvami_crab_Analysis_2018_TTToSemiLeptonic_wProbQ_CodeV19p1_v1                              |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#7eb63786-b88c-4355-a298-e6399c57f75d    |8.31920897E8     |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#f362a122-62e0-49b7-bdbb-02f7b7210732    |8.65833734E10    |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#90f337a0-f719-4e8e-8760-fa512b2d3067    |2.5523501484E10  |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440961000|1651441731000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#38e5ecb7-0d1a-4899-b549-2043e4db0078    |8.25686611E8     |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651442199000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#63948ae4-646b-4acb-9a0c-c65539b552b5    |8.31130538E8     |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440961000|1651440961000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#63bd6774-0807-48df-9979-e718ef32ffde    |8.0037294459E10  |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#f4dbc3f2-06ad-421e-9c46-5f52aa5df039    |3.44675933978E11 |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#0871b8ad-fb83-4f5f-98d7-8cc43e243f3c    |3.32558559485E11 |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#da57f963-03d6-4580-b059-3f632f20c421    |6.6817244069E10  |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#012fe5e5-e750-446e-b4cd-5a5b9feb80a6    |3.312155276E9    |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440961000|1651440961000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#0aaaad04-1f7c-478b-b762-5322af391d23    |1.03104236178E11 |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#f6970763-5f06-4b20-bc72-043d01dca735    |2.30191345941E11 |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651442382000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#7fe33987-9e51-46a4-8eb1-09793d25f137    |8.7612003985E10  |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#37087eea-5839-4b20-9b0b-e507806269dd    |1.33811516676E11 |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651440961000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#f83a5b87-e4a7-4ab8-bb4b-8d9c19ff0dfa    |3.5506129769E10  |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651440961000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#827113b5-e106-43ad-8b41-aadf6fbd44a5    |6.1083219261E10  |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#1d322ee8-7004-477d-a63d-e4e6d80a11b4    |3.6253085509E10  |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651440961000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#fda72e7c-4372-4201-96d8-cf8f2775257d    |9.894191869E9    |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651356722000|1651442397000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#1d6271a0-26e7-4452-87cf-7c7a0595c029    |3.05197898886E11 |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651442320000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#1cd693ec-468c-43d8-b4e6-8af5a5dfb696    |9.3566542277E11  |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651442395000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#ae46576b-c270-4177-92e7-3111c7c202bd    |1.1639717243E12  |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651376170000|1651442375000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#54f3559f-2622-46ca-b1f9-e7bd715d9e64    |1.20385236467E11 |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651441682000|\n",
      "|AODSIM            |/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM    |1.43352216877764E14|/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/RunIISummer20UL18RECO-106X_upgrade2018_realistic_v11_L1v1-v2/AODSIM#b1c529c9-6af0-4a81-88f5-9cb46b979568    |3.299936754E9    |220501_211425:tvami_crab_Analysis_2018_TTToHadronic_wProbQ_CodeV19p1_v1                                  |1651440241000|1651442079000|\n",
      "|AOD               |/HIMinimumBias5/HIRun2018A-04Apr2019-v1/AOD                                                                       |1.03519806474904E14|/HIMinimumBias5/HIRun2018A-04Apr2019-v1/AOD#b2085000-0a03-4240-9647-312105737715                                                                       |1.551625764434E12|220430_213949:prabhat_crab_PbPb2018_AODHI05_v22q3_dbyr_mult_eff_pt0p5_5p0_etamod2p4_cent3040_Apr30_2022_0|1651356001000|1651441682000|\n",
      "|AOD               |/HIMinimumBias6/HIRun2018A-04Apr2019-v1/AOD                                                                       |1.03364823728415E14|/HIMinimumBias6/HIRun2018A-04Apr2019-v1/AOD#4d353627-7dce-47da-bcd4-30e7665af5a9                                                                       |6.0771363239E10  |220424_105118:subehera_crab_MB6_2030_April24_highpT_PbPb2018                                             |1651356001000|1651442355000|\n",
      "|AOD               |/HIMinimumBias11/HIRun2018A-04Apr2019-v1/AOD                                                                      |1.02453605394954E14|/HIMinimumBias11/HIRun2018A-04Apr2019-v1/AOD#92888fe5-af93-439e-9982-d283df38a89f                                                                      |2.969310019E9    |220430_230228:nsaha_crab_PbPb2018_AODHI11_v22q3_rbyd_mult_eff_pt0p5_5p0_etamod2p4_cent3040_May01_2022_0  |1651357440000|1651362845000|\n",
      "+------------------+------------------------------------------------------------------------------------------------------------------+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------------------------------------------------------------------------------------------------------+-------------+-------------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(40,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be6ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2c89f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eab8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d49c97b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "sparkconnect": {
   "bundled_options": [],
   "list_of_options": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
